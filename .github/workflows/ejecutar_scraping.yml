name: Ejecutar Scraper Diario

on:
  schedule:
    - cron: '56 17 * * *'   # 17:56 UTC (19:56 Madrid en verano)
  workflow_dispatch:

# Hace que todos los 'run:' se ejecuten dentro de ./scrapping
defaults:
  run:
    shell: bash
    working-directory: scrapping

jobs:
  run-script:
    runs-on: ubuntu-latest

    # üîê Exporta los secretos como variables de entorno para el job completo
    env:
      SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
      SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
      SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}   # ej: wynifvb-ye01854 (sin .snowflakecomputing.com)
      SNOWFLAKE_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
      SNOWFLAKE_DATABASE: ${{ secrets.SNOWFLAKE_DATABASE }}
      SNOWFLAKE_SCHEMA: ${{ secrets.SNOWFLAKE_SCHEMA }}

    steps:
      - name: Clonar repositorio
        uses: actions/checkout@v3

      - name: Configurar Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('scrapping/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Instalar dependencias
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # ‚úÖ Paso de depuraci√≥n (opcional): confirma que llegan las vars (sin exponer password)
      - name: Debug entorno Snowflake (safe)
        run: |
          echo "SF_USER=$SNOWFLAKE_USER"
          echo "SF_ACCOUNT=$SNOWFLAKE_ACCOUNT"
          echo "SF_WAREHOUSE=$SNOWFLAKE_WAREHOUSE"
          echo "SF_DATABASE=$SNOWFLAKE_DATABASE"
          echo "SF_SCHEMA=$SNOWFLAKE_SCHEMA"
          test -n "$SNOWFLAKE_PASSWORD" && echo "SF_PASSWORD=*** (seteada)" || (echo "SF_PASSWORD=FALTA" && exit 1)

      - name: Ejecutar script principal
        run: |
          echo "üìÖ Ejecutando main.py el $(date -u)"
          python main.py

      # 1) Webhook: scraping-finalizado
      - name: Notificar a n8n - scraping finalizado
        if: success()
        env:
          N8N_URL: ${{ secrets.N8N_URL }}
          N8N_WEBHOOK_SECRET: ${{ secrets.N8N_WEBHOOK_SECRET }}
        run: |
          set -euo pipefail
          curl -sS --fail --retry 3 -X POST "$N8N_URL/webhook/scraping-finalizado" \
            -H "Content-Type: application/json" \
            -H "x-n8n-secret: $N8N_WEBHOOK_SECRET" \
            --data @- <<'JSON'
          {
            "status": "success",
            "mensaje": "‚úÖ Scraping finalizado correctamente en GitHub Actions",
            "timestamp": "${{ github.run_started_at }}",
            "run_id": "${{ github.run_id }}",
            "workflow": "${{ github.workflow }}",
            "repository": "${{ github.repository }}",
            "sha": "${{ github.sha }}"
          }
          JSON

      # 2) Webhook: actualizar-registros
      - name: Notificar a n8n - actualizar registros
        if: success()
        env:
          N8N_URL: ${{ secrets.N8N_URL }}
          N8N_WEBHOOK_SECRET: ${{ secrets.N8N_WEBHOOK_SECRET }}
        run: |
          set -euo pipefail
          curl -sS --fail --retry 3 -X POST "$N8N_URL/webhook/actualizar-registros" \
            -H "Content-Type: application/json" \
            -H "x-n8n-secret: $N8N_WEBHOOK_SECRET" \
            --data @- <<'JSON'
          {
            "status": "success",
            "mensaje": "üîÑ Actualizar registros tras scraping",
            "run_id": "${{ github.run_id }}",
            "workflow": "${{ github.workflow }}",
            "repository": "${{ github.repository }}",
            "sha": "${{ github.sha }}"
          }
          JSON
